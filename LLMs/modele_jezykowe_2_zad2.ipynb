{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "model_name = \"eryk-mazus/polka-1.1b-chat\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map={\"\": \"cpu\"}\n",
        ")\n",
        "\n",
        "\n",
        "allowed_words = [\"skarpetki\", \"traktor\", \"ryba\", \"jabłko\", \"chleb\"]\n",
        "allowed_ids = [tokenizer.encode(word, add_special_tokens=False) for word in allowed_words]\n",
        "max_allowed_length = max(len(seq) for seq in allowed_ids)  # Maksymalna długość ciągu w allowed_ids\n",
        "print(\"Allowed ids:\", allowed_ids)\n",
        "print(\"Max allowed sequence length:\", max_allowed_length)\n",
        "\n",
        "\n",
        "few_shot_examples = (\n",
        "    \"Zagadka: Co szczeka i jest najlepszym przyjacielem człowieka? Odpowiedź to jedno słowo: pies\\n\"\n",
        "    \"Zagadka: Co ma cztery nogi i jest zwierzęciem domowym? Odpowiedź to jedno słowo: kot\\n\"\n",
        "    \"Zagadka: Co jest przezroczyste, cieczy i jest niezbędne do życia? Odpowiedź to jedno słowo: woda\\n\\n\"\n",
        ")\n",
        "\n",
        "\n",
        "riddles = [\n",
        "    \"Zagadka: Co jest słodkie, czerwone i można je zjeść? Odpowiedź to jedno słowo:\",\n",
        "    \"Zagadka: Co to za część garderoby, którą zakładamy na stopy przed założeniem butów? Odpowiedź to jedno słowo:\",\n",
        "    \"Zagadka: Co to za pokarm, powstaje z mąki i wody? Odpowiedź to jedno słowo:\"\n",
        "]\n",
        "\n",
        "\n",
        "prompts = [few_shot_examples + riddle for riddle in riddles]\n",
        "\n",
        "def generate_single_word(model, input_ids, allowed_ids, max_length):\n",
        "    output_ids = input_ids.clone()\n",
        "    valid_word = False\n",
        "\n",
        "\n",
        "    allowed_tokens = list(set([token for seq in allowed_ids for token in seq]))\n",
        "\n",
        "    while not valid_word and output_ids.shape[1] - input_ids.shape[1] <= max_length:\n",
        "        with torch.no_grad():\n",
        "            logits = model(output_ids).logits[:, -1, :] #(batch_size=1 (bo generujemy jenda odpowiedz), sequence_length, vocab_size)\n",
        "            # maskujemy wszystkie tokeny, które nie należą do allowed_tokens\n",
        "            mask = torch.full_like(logits, float(\"-inf\"))\n",
        "            mask[:, allowed_tokens] = logits[:, allowed_tokens]  # pozostawiamy tylko dozwolone tokeny\n",
        "            logits = mask\n",
        "            # wybieramy token o najwyższym prawdopodobieństwie spośród allowed_tokens\n",
        "            top_token = torch.argmax(logits, dim=-1, keepdim=True)\n",
        "            output_ids = torch.cat([output_ids, top_token], dim=-1)\n",
        "            print(\"Generated token:\", top_token)\n",
        "\n",
        "        # sprawdzanie, czy końcowa sekwencja odpowiada któremuś z allowed_ids\n",
        "        for allowed_seq in allowed_ids:\n",
        "            if output_ids[0, -len(allowed_seq):].tolist() == allowed_seq:\n",
        "                valid_word = True\n",
        "                return tokenizer.decode(allowed_seq)  # zwracamy pełne słowo jako tekst\n",
        "\n",
        "\n",
        "all_responses = {}\n",
        "\n",
        "for prompt, riddle in zip(prompts, riddles):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to(model.device)\n",
        "\n",
        "    responses = []\n",
        "    for _ in tqdm(range(3), desc=f\"Processing riddle: '{riddle[:50]}...'\"):\n",
        "        response = generate_single_word(model, input_ids, allowed_ids, max_allowed_length)\n",
        "        responses.append(response)\n",
        "\n",
        "    all_responses[riddle] = responses\n",
        "\n",
        "\n",
        "for riddle, responses in all_responses.items():\n",
        "    print(f\"{riddle}\\nWygenerowane odpowiedzi: {responses}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rpkuE4C9N_e-",
        "outputId": "10cf93a7-6ee6-45ff-ae03-2ca0f2f4acd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allowed ids: [[2071, 6834, 300, 1984], [1020, 10407], [24721, 2291], [432, 370, 30006, 2901], [521, 19982]]\n",
            "Max allowed sequence length: 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...':   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[432]])\n",
            "Generated token: tensor([[370]])\n",
            "Generated token: tensor([[30006]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...':  33%|███▎      | 1/3 [00:28<00:57, 28.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[2901]])\n",
            "Generated token: tensor([[432]])\n",
            "Generated token: tensor([[370]])\n",
            "Generated token: tensor([[30006]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...':  67%|██████▋   | 2/3 [00:53<00:26, 26.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[2901]])\n",
            "Generated token: tensor([[432]])\n",
            "Generated token: tensor([[370]])\n",
            "Generated token: tensor([[30006]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...': 100%|██████████| 3/3 [01:17<00:00, 25.95s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[2901]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...':   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[2071]])\n",
            "Generated token: tensor([[6834]])\n",
            "Generated token: tensor([[300]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...':  33%|███▎      | 1/3 [00:25<00:50, 25.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[1984]])\n",
            "Generated token: tensor([[2071]])\n",
            "Generated token: tensor([[6834]])\n",
            "Generated token: tensor([[300]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...':  67%|██████▋   | 2/3 [00:50<00:24, 24.99s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[1984]])\n",
            "Generated token: tensor([[2071]])\n",
            "Generated token: tensor([[6834]])\n",
            "Generated token: tensor([[300]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...': 100%|██████████| 3/3 [01:21<00:00, 27.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[1984]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...':   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[521]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...':  33%|███▎      | 1/3 [00:14<00:29, 14.77s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[19982]])\n",
            "Generated token: tensor([[521]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...':  67%|██████▋   | 2/3 [00:28<00:14, 14.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[19982]])\n",
            "Generated token: tensor([[521]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...': 100%|██████████| 3/3 [00:40<00:00, 13.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[19982]])\n",
            "Zagadka: Co jest słodkie, czerwone i można je zjeść? Odpowiedź to jedno słowo:\n",
            "Wygenerowane odpowiedzi: ['jabłko', 'jabłko', 'jabłko']\n",
            "\n",
            "Zagadka: Co to za część garderoby, którą zakładamy na stopy przed założeniem butów? Odpowiedź to jedno słowo:\n",
            "Wygenerowane odpowiedzi: ['skarpetki', 'skarpetki', 'skarpetki']\n",
            "\n",
            "Zagadka: Co to za pokarm, powstaje z mąki i wody? Odpowiedź to jedno słowo:\n",
            "Wygenerowane odpowiedzi: ['chleb', 'chleb', 'chleb']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model_name = 'flax-community/papuGaPT2'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    torch_dtype=torch.float32,\n",
        "    device_map={\"\": \"cpu\"}\n",
        ")\n",
        "\n",
        "\n",
        "allowed_words = [\"skarpetki\", \"traktor\", \"ryba\", \"jabłko\", \"chleb\"]\n",
        "allowed_ids = [tokenizer.encode(word, add_special_tokens=False) for word in allowed_words]\n",
        "max_allowed_length = max(len(seq) for seq in allowed_ids)  # Maksymalna długość ciągu w allowed_ids\n",
        "print(\"Allowed ids:\", allowed_ids)\n",
        "print(\"Max allowed sequence length:\", max_allowed_length)\n",
        "\n",
        "\n",
        "all_responses = {}\n",
        "\n",
        "for prompt, riddle in zip(prompts, riddles):\n",
        "    input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
        "    input_ids = input_ids.to(model.device)\n",
        "\n",
        "    responses = []\n",
        "    for _ in tqdm(range(3), desc=f\"Processing riddle: '{riddle[:50]}...'\"):\n",
        "        response = generate_single_word(model, input_ids, allowed_ids, max_allowed_length)\n",
        "        responses.append(response)\n",
        "\n",
        "    all_responses[riddle] = responses\n",
        "\n",
        "\n",
        "for riddle, responses in all_responses.items():\n",
        "    print(f\"{riddle}\\nWygenerowane odpowiedzi: {responses}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd7VzWp3QI20",
        "outputId": "9c85d0d7-5405-4c7a-ad68-ba2f67a45c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Allowed ids: [[5702, 483, 946], [7630, 716], [335, 491], [317, 70, 9735], [274, 7012]]\n",
            "Max allowed sequence length: 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...':   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...':  33%|███▎      | 1/3 [00:02<00:04,  2.10s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...':  67%|██████▋   | 2/3 [00:03<00:01,  1.70s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing riddle: 'Zagadka: Co jest słodkie, czerwone i można je zjeś...': 100%|██████████| 3/3 [00:04<00:00,  1.64s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...':   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...':  33%|███▎      | 1/3 [00:01<00:02,  1.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...':  67%|██████▋   | 2/3 [00:02<00:01,  1.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing riddle: 'Zagadka: Co to za część garderoby, którą zakładamy...': 100%|██████████| 3/3 [00:04<00:00,  1.48s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...':   0%|          | 0/3 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...':  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rProcessing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...':  67%|██████▋   | 2/3 [00:03<00:01,  1.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Generated token: tensor([[317]])\n",
            "Generated token: tensor([[70]])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing riddle: 'Zagadka: Co to za pokarm, powstaje z mąki i wody? ...': 100%|██████████| 3/3 [00:05<00:00,  1.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated token: tensor([[9735]])\n",
            "Zagadka: Co jest słodkie, czerwone i można je zjeść? Odpowiedź to jedno słowo:\n",
            "Wygenerowane odpowiedzi: ['jabłko', 'jabłko', 'jabłko']\n",
            "\n",
            "Zagadka: Co to za część garderoby, którą zakładamy na stopy przed założeniem butów? Odpowiedź to jedno słowo:\n",
            "Wygenerowane odpowiedzi: ['jabłko', 'jabłko', 'jabłko']\n",
            "\n",
            "Zagadka: Co to za pokarm, powstaje z mąki i wody? Odpowiedź to jedno słowo:\n",
            "Wygenerowane odpowiedzi: ['jabłko', 'jabłko', 'jabłko']\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}